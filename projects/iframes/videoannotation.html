<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
	<title>Video Annotation Tool</title>
	<link rel="stylesheet" href="../../css/iframe.css" type="text/css" media="screen" />
</head>

<body>
	<p>The Mixed Reality Rehabilitation team at Arizona State University has developed an adaptive, mixed reality rehabilitation (AMMR) system to train reaching and grasping movements of stroke survivors. The AMRR system integrates rehabilitation and motor learning theories with high-resolution motion capture and sensing technologies, smart physical objects, and interactive computer graphics and sound. A key component of this system is the development of a novel computational measure - the Kinematic Impairment Measure (KIM) - to evaluate the stroke survivor's movement performance during the task. Detailed results from the KIM are provided in real-time to the clinician, and can be used to inform the clinician's patient recommendations and system adaptation refinements. </p>
	<p>We recently completed a clinical study of the AMMR system with 20 stroke survivors. Each session was video-recorded and archived along with the detailed multimodal data generated during therapy. The purpose of the system proposed in this document is to develop an online assessment environment where expert physiotherapists can review, compare and annotate patient videos using an appropriate categorization schema. Previous studies highlight the challenges in identifying quality of movement rating schemas with high interrater reliability . Our proposed assessment system will provide therapists with a constrained set of positive and negative movement annotations. The videos will be presented to the therapists as an AB comparison, where they will be asked to specify which video of the pair demonstrates best patient movement quality, and then annotate each using the provided schema. The therapists will be able to view editable summaries of their annotations and re-watch or review any of the video content provided. The system will log all of the therapist interactions including, for example, video playback and re-view, length of time spent on task, amount of annotation editing etc. The therapists will also be able to save their annotations in draft form, thus allowing them to complete their final submission over several sessions if required.</p>
	<p>There are several key challenges in developing this work including 1) developing an appropriate quality of movement annotation schema; 2) designing an intuitive user interface; 3) accurately tracking all system interactions; and 4) ensuring the security and remote accessibility of the video content. We would require input and advice from you as we develop and test our system in response to each of these challenges (e.g. helping us refine the annotation schema, providing feedback about the end-user experience with our tool prototype etc.)</p>
	<p>Dr. Steve Wolf has provided us with a preliminary draft of the quality of movement annotation schema. The schema provides 7 primary attribute categories, with indented terms defined as indicating positive or negative movements. </p>
</body>
</html>
